{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3.7.3 64-bit ('base': conda)","language":"python","name":"python373jvsc74a57bd0f057f675914b11b512bf379bae07be6e1618e8fe1362d0973cc146d2f4f584aa"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"P7-04_prognose_QU.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NFybGhH1OtDT"},"source":["# P5-04: Prediction and post-processing of the masks\n","Post-processing with two versions:\n","- Contour code, standard library\n","- Chain code in python"]},{"cell_type":"markdown","metadata":{"id":"YuQFzLWFQOou"},"source":["## Set up Google Colab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwvt7pEcQTGL","executionInfo":{"status":"ok","timestamp":1629976446522,"user_tz":-120,"elapsed":787,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"65127ee2-3e5d-45a9-982d-712dd988a6bc"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f77-ya8KQTbb","executionInfo":{"status":"ok","timestamp":1629976448160,"user_tz":-120,"elapsed":1288,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"25429f15-74d6-4538-8287-dc04c6442038"},"source":["cd drive/MyDrive/BA_SemanticSegmentation_JonasHeinke/___P7_Eigenes_Projekt_Segmentation_QU/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1i0GOg0AT_UuZJJUMz0D46PD2S2VfYbPB/NN_Segmentation/BA_Semantische_Segmentation/_Skript_Projekte\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96rsJTyqQT5T","executionInfo":{"status":"ok","timestamp":1629976448645,"user_tz":-120,"elapsed":489,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"7c0a9596-c170-4a61-e2d1-52969f726140"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Codeoptimierung_Hinweise.py\n","\u001b[0m\u001b[01;34m___Datasets\u001b[0m/\n","\u001b[01;34m___P3-1_UNET-RESNET_NODE-PL-Segmenation_QU\u001b[0m/\n","\u001b[01;34m___P3_neural-odes-segmentation-master_QU\u001b[0m/\n","\u001b[01;34m___P4-1_UNET-PL_Segmentation_CRAG\u001b[0m/\n","\u001b[01;34m___P4_neural-odes-segmentation-master_CRAG\u001b[0m/\n","\u001b[01;34m___P5_Eigenes_Projekt_Segmentation_CRAG\u001b[0m/\n","\u001b[01;34m___P7_Eigenes_Projekt_Segmentation_QU\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIN1Ul_UQcdC","executionInfo":{"status":"ok","timestamp":1629976448646,"user_tz":-120,"elapsed":5,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"f863708e-fa07-4d63-e673-0280b1426600"},"source":["cd ___P7_Eigenes_Projekt_Segmentation_QU/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1i0GOg0AT_UuZJJUMz0D46PD2S2VfYbPB/NN_Segmentation/BA_Semantische_Segmentation/_Skript_Projekte/___P7_Eigenes_Projekt_Segmentation_QU\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r96hU2CSQUtD"},"source":["## Libraries, modules"]},{"cell_type":"code","metadata":{"id":"wOHAcw_pOtDU"},"source":["# Imports\n","import pathlib\n","import numpy as np\n","import torch\n","from skimage.io import imread\n","from skimage.transform import resize\n","import os\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pickle # zum speichern\n","#------------------------------------------------------------------\n","from  MODULE.PL.metrics import ObjectDice, ObjectHausdorff, F1score\n","#---------------\n","#from MODULE.JS.inference import predict\n","from MODULE.JS.transformations import normalize_01, re_normalize\n","from MODULE.JS.unet import UNet\n","#------------\n","# Konfigurationsdaten\n","from configuration_QU import Path   as PATH   # Pfade und Dateinamen\n","from configuration_QU import Inputs as INPUT    # Imageparameter\n","from configuration_QU import CfgModel as CFG_MODEL  # Modellparameter\n","from configuration_QU import Postprocess as POST  # Nachbearbeitung\n","from configuration_QU import EXPERIMENT          # Name des Experiments\n","# Transformationen und Anpassungen\n","from MODULE.JH.img_array_transform import ArrayTransform as TRANSFORM\n","# Bildoperationen, Kettencode\n","import MODULE.JH.image_processing as IP\n","# Prognose mit Anpassungen\n","from MODULE.JH.prediction import Prediction as PREDICTION\n","# View Bild-Masken-Sets\n","from MODULE.JH.visualize import Show as SHOW\n","# Instanzen von Klassen ggf.\n","transform=TRANSFORM() # Klassenistanz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yywp3K0uOtDV","executionInfo":{"status":"ok","timestamp":1629976458932,"user_tz":-120,"elapsed":43,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"f0ee2503-6b8d-4d3e-b285-4f7a4e6fa9b9"},"source":["# Printkontrolle\n","VERBOSE=True\n","# Experiment, Daten aus dem Training\n","print(EXPERIMENT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["QU_vgl(open8x8_2021-08-26)_blocks7_cout2_optAdam_lr0.001_ep600_h512_w768_ft64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-T9H1DdBOtDW"},"source":["## List of file paths of the test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPfh23Y1OtDW","executionInfo":{"status":"ok","timestamp":1629976458932,"user_tz":-120,"elapsed":36,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"36c48da4-7f9f-4e6e-9779-ad44e94df03f"},"source":["path=PATH() # Instanz der Klasse für Methodenaufruf erforderlich\n","path_images=path.testimages\n","path_masks=path.testmasks\n","# Source path of the trained model.\n","path_model_experiment=path.model / EXPERIMENT\n","# Destination path for results of the experiment\n","path_result_experiment   = path.results  / EXPERIMENT\n","if not os.path.exists(path_result_experiment):\n","    os.mkdir(path_result_experiment)\n","# Filter\n","imgfilter= ['train_??.bmp',       'testA_??.bmp',     'testB_??.bmp']\n","maskfilter=['train_??_anno.bmp', 'testA_??_anno.bmp', 'testB_??_anno.bmp']\n","fidx=1\n","if path.serie=='B':\n","    fidx=2\n","# input and target files -TRAIN[0], TESTA[1], TESTB[2]\n","image_filenames = path.get_filenames(path_images, dateifilter= imgfilter[fidx],  sort=True)\n","mask_filenames  = path.get_filenames(path_masks,  dateifilter= maskfilter[fidx], sort=True)\n","if VERBOSE:\n","    print('Serie: ', path.serie)\n","    print(path_images)\n","    print(path_masks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Serie:  A\n","/content/drive/.shortcut-targets-by-id/1i0GOg0AT_UuZJJUMz0D46PD2S2VfYbPB/NN_Segmentation/BA_Semantische_Segmentation/_Skript_Projekte/___P7_Eigenes_Projekt_Segmentation_QU/Warwick QU Dataset (Released 2016_07_08)\n","/content/drive/.shortcut-targets-by-id/1i0GOg0AT_UuZJJUMz0D46PD2S2VfYbPB/NN_Segmentation/BA_Semantische_Segmentation/_Skript_Projekte/___P7_Eigenes_Projekt_Segmentation_QU/Warwick QU Dataset (Released 2016_07_08)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UeZ3GByOtDW","executionInfo":{"status":"ok","timestamp":1629976458933,"user_tz":-120,"elapsed":30,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"10b3e346-1b2c-4944-c6fe-f8da31bb2823"},"source":["print('Anzahl der Bild-Masken-Paare (Samples) für Prognose: ',len(image_filenames),' : ', len(mask_filenames))\n","if VERBOSE:\n","    for idx in range(len(image_filenames)):\n","        print(idx, ' | ', os.path.basename(image_filenames[idx]),'\\t-> ', os.path.basename(mask_filenames[idx]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Anzahl der Bild-Masken-Paare (Samples) für Prognose:  60  :  60\n","0  |  testA_01.bmp \t->  testA_01_anno.bmp\n","1  |  testA_02.bmp \t->  testA_02_anno.bmp\n","2  |  testA_03.bmp \t->  testA_03_anno.bmp\n","3  |  testA_04.bmp \t->  testA_04_anno.bmp\n","4  |  testA_05.bmp \t->  testA_05_anno.bmp\n","5  |  testA_06.bmp \t->  testA_06_anno.bmp\n","6  |  testA_07.bmp \t->  testA_07_anno.bmp\n","7  |  testA_08.bmp \t->  testA_08_anno.bmp\n","8  |  testA_09.bmp \t->  testA_09_anno.bmp\n","9  |  testA_10.bmp \t->  testA_10_anno.bmp\n","10  |  testA_11.bmp \t->  testA_11_anno.bmp\n","11  |  testA_12.bmp \t->  testA_12_anno.bmp\n","12  |  testA_13.bmp \t->  testA_13_anno.bmp\n","13  |  testA_14.bmp \t->  testA_14_anno.bmp\n","14  |  testA_15.bmp \t->  testA_15_anno.bmp\n","15  |  testA_16.bmp \t->  testA_16_anno.bmp\n","16  |  testA_17.bmp \t->  testA_17_anno.bmp\n","17  |  testA_18.bmp \t->  testA_18_anno.bmp\n","18  |  testA_19.bmp \t->  testA_19_anno.bmp\n","19  |  testA_20.bmp \t->  testA_20_anno.bmp\n","20  |  testA_21.bmp \t->  testA_21_anno.bmp\n","21  |  testA_22.bmp \t->  testA_22_anno.bmp\n","22  |  testA_23.bmp \t->  testA_23_anno.bmp\n","23  |  testA_24.bmp \t->  testA_24_anno.bmp\n","24  |  testA_25.bmp \t->  testA_25_anno.bmp\n","25  |  testA_26.bmp \t->  testA_26_anno.bmp\n","26  |  testA_27.bmp \t->  testA_27_anno.bmp\n","27  |  testA_28.bmp \t->  testA_28_anno.bmp\n","28  |  testA_29.bmp \t->  testA_29_anno.bmp\n","29  |  testA_30.bmp \t->  testA_30_anno.bmp\n","30  |  testA_31.bmp \t->  testA_31_anno.bmp\n","31  |  testA_32.bmp \t->  testA_32_anno.bmp\n","32  |  testA_33.bmp \t->  testA_33_anno.bmp\n","33  |  testA_34.bmp \t->  testA_34_anno.bmp\n","34  |  testA_35.bmp \t->  testA_35_anno.bmp\n","35  |  testA_36.bmp \t->  testA_36_anno.bmp\n","36  |  testA_37.bmp \t->  testA_37_anno.bmp\n","37  |  testA_38.bmp \t->  testA_38_anno.bmp\n","38  |  testA_39.bmp \t->  testA_39_anno.bmp\n","39  |  testA_40.bmp \t->  testA_40_anno.bmp\n","40  |  testA_41.bmp \t->  testA_41_anno.bmp\n","41  |  testA_42.bmp \t->  testA_42_anno.bmp\n","42  |  testA_43.bmp \t->  testA_43_anno.bmp\n","43  |  testA_44.bmp \t->  testA_44_anno.bmp\n","44  |  testA_45.bmp \t->  testA_45_anno.bmp\n","45  |  testA_46.bmp \t->  testA_46_anno.bmp\n","46  |  testA_47.bmp \t->  testA_47_anno.bmp\n","47  |  testA_48.bmp \t->  testA_48_anno.bmp\n","48  |  testA_49.bmp \t->  testA_49_anno.bmp\n","49  |  testA_50.bmp \t->  testA_50_anno.bmp\n","50  |  testA_51.bmp \t->  testA_51_anno.bmp\n","51  |  testA_52.bmp \t->  testA_52_anno.bmp\n","52  |  testA_53.bmp \t->  testA_53_anno.bmp\n","53  |  testA_54.bmp \t->  testA_54_anno.bmp\n","54  |  testA_55.bmp \t->  testA_55_anno.bmp\n","55  |  testA_56.bmp \t->  testA_56_anno.bmp\n","56  |  testA_57.bmp \t->  testA_57_anno.bmp\n","57  |  testA_58.bmp \t->  testA_58_anno.bmp\n","58  |  testA_59.bmp \t->  testA_59_anno.bmp\n","59  |  testA_60.bmp \t->  testA_60_anno.bmp\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N5y9VCTfOtDX"},"source":["## Read in images and masks\n","- The size of the test images and test masks correspond to the training. Scaling is done accordingly."]},{"cell_type":"code","metadata":{"id":"SIOWcZQpOtDX"},"source":["# read images and store them in memory\n","images = [imread(img_name) for img_name in image_filenames]\n","actual_masks = [imread(mask_name) for mask_name in mask_filenames]\n","# Resize images and targets\n","images_res = [resize(img, (INPUT.h_res, INPUT.w_res, INPUT.c_res)) for img in images]\n","resize_kwargs = {'order': 0, 'anti_aliasing': False, 'preserve_range': True}\n","actual_masks_res = [resize(mask, (INPUT.h_res, INPUT.w_res), **resize_kwargs) for mask in actual_masks]\n","\n","# Anzahl der Stichproben\n","sample_anzahl=len(images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-TApwzNOtDY"},"source":["## Set up the model\n","Prediction parameters must correspond to the training parameters. Common configuration supports this process."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JCtepA7YOtDY","executionInfo":{"status":"error","timestamp":1629976874030,"user_tz":-120,"elapsed":7299,"user":{"displayName":"jon jon","photoUrl":"","userId":"11545148206954630185"}},"outputId":"d6cea655-7d37-4f91-cab0-04d820a63558"},"source":["# Determination of the available device (CPU, GPU).\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# model\n","model = UNet(in_channels=INPUT.c_res,\n","             out_channels= CFG_MODEL.c_out,\n","             n_blocks=CFG_MODEL.n_blocks,\n","             start_filters=CFG_MODEL.ft,\n","             activation='relu',\n","             normalization='batch',\n","             conv_mode='same',\n","             dim=2).to(device)\n","model_weights = torch.load(path_model_experiment/ 'model')\n","model.load_state_dict(model_weights)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-de7d088b017c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m              dim=2).to(device)\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_model_experiment\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tsize mismatch for conv_final.weight: copying a param with shape torch.Size([2, 32, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 64, 1, 1]).\n\tsize mismatch for down_blocks.0.conv1.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).\n\tsize mismatch for down_blocks.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for down_blocks.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm1.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm1.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm2.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.0.norm2.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for down_blocks.1.conv1.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for down_blocks.1.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for down_blocks.1.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.1.norm2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for down_blocks.2.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for down_blocks.2.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for down_blocks.2.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.2.norm2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for down_blocks.3.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for down_blocks.3.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for down_blocks.3.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.3.norm2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for down_blocks.4.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3, 3]).\n\tsize mismatch for down_blocks.4.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for down_blocks.4.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.4.norm2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for down_blocks.5.conv1.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 3, 3]).\n\tsize mismatch for down_blocks.5.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.conv2.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for down_blocks.5.conv2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.5.norm2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for down_blocks.6.conv1.weight: copying a param with shape torch.Size([2048, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([4096, 2048, 3, 3]).\n\tsize mismatch for down_blocks.6.conv1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.conv2.weight: copying a param with shape torch.Size([2048, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([4096, 4096, 3, 3]).\n\tsize mismatch for down_blocks.6.conv2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for down_blocks.6.norm2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for up_blocks.0.up.weight: copying a param with shape torch.Size([2048, 1024, 2, 2]) from checkpoint, the shape in current model is torch.Size([4096, 2048, 2, 2]).\n\tsize mismatch for up_blocks.0.up.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.conv0.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 1, 1]).\n\tsize mismatch for up_blocks.0.conv0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.conv1.weight: copying a param with shape torch.Size([1024, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 3, 3]).\n\tsize mismatch for up_blocks.0.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.conv2.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for up_blocks.0.conv2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm0.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm0.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm0.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.0.norm2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for up_blocks.1.up.weight: copying a param with shape torch.Size([1024, 512, 2, 2]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 2, 2]).\n\tsize mismatch for up_blocks.1.up.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.conv0.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 1, 1]).\n\tsize mismatch for up_blocks.1.conv0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 3, 3]).\n\tsize mismatch for up_blocks.1.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for up_blocks.1.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm0.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm0.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.1.norm2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for up_blocks.2.up.weight: copying a param with shape torch.Size([512, 256, 2, 2]) from checkpoint, the shape in current model is torch.Size([1024, 512, 2, 2]).\n\tsize mismatch for up_blocks.2.up.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.conv0.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for up_blocks.2.conv0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\n\tsize mismatch for up_blocks.2.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for up_blocks.2.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm0.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm0.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm0.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.2.norm2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for up_blocks.3.up.weight: copying a param with shape torch.Size([256, 128, 2, 2]) from checkpoint, the shape in current model is torch.Size([512, 256, 2, 2]).\n\tsize mismatch for up_blocks.3.up.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.conv0.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for up_blocks.3.conv0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for up_blocks.3.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for up_blocks.3.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm0.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm0.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm0.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.3.norm2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for up_blocks.4.up.weight: copying a param with shape torch.Size([128, 64, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 128, 2, 2]).\n\tsize mismatch for up_blocks.4.up.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.conv0.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for up_blocks.4.conv0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.conv1.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n\tsize mismatch for up_blocks.4.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for up_blocks.4.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm0.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm0.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.4.norm2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for up_blocks.5.up.weight: copying a param with shape torch.Size([64, 32, 2, 2]) from checkpoint, the shape in current model is torch.Size([128, 64, 2, 2]).\n\tsize mismatch for up_blocks.5.up.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.conv0.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for up_blocks.5.conv0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.conv1.weight: copying a param with shape torch.Size([32, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for up_blocks.5.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for up_blocks.5.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm0.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm0.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm0.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm1.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm1.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm2.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for up_blocks.5.norm2.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64])."]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"l_c5FD0IOtDY"},"source":["# Prediction of the segmentation mask\n","prediction=PREDICTION(model, device, True)\n","predict_masks = [prediction.mask(img) for img in images_res]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"APoxAuRVOtDY"},"source":["## Evaluation of the prognosis of the test set\n","- Here just for checking purposes, see project \"P7-05 result visualization\""]},{"cell_type":"code","metadata":{"id":"graPWRpwOtDZ"},"source":["transform=TRANSFORM()\n","dice, hausdorff, f1, dice_full = 0, 0, 0, 0\n","i_error=0\n","anzahl=0\n","# Table header\n","print_string=(f' idx | dice_img  | f1_img    | hausdorff_img | result-filename | input-filename')\n","print(print_string)\n","for idx in range(sample_anzahl):\n","    try:\n","        predict_mask_two= transform.twoClasses(predict_masks[idx])\n","        actual_masks_two= transform.twoClasses(actual_masks_res[idx])\n","        dice_img = ObjectDice(predict_mask_two,        actual_masks_two)\n","        f1_img = F1score(predict_mask_two,              actual_masks_two)\n","        hausdorff_img = ObjectHausdorff(predict_mask_two,  actual_masks_two)\n","        dice += dice_img\n","        f1 += f1_img\n","        hausdorff += hausdorff_img\n","        print_string=(f' {idx:3d} | {dice_img:9.3f} | {f1_img:9.3f} | {hausdorff_img:13.3f} | result_test_{idx:-02d}  | {os.path.basename(mask_filenames[idx])}')\n","        print(print_string)\n","        anzahl +=1\n","    except:\n","        i_error +=1\n","        print('Error: ',i_error, 'Cycle: ', idx)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQ7kzTz5OtDZ"},"source":["print('-- Mean values ------------------------------------')\n","print('ObjectDice:', dice / anzahl )\n","print('F1:', f1 / anzahl )\n","print('Weighted shape:', hausdorff / anzahl)\n","print('Number io.: ', anzahl)\n","print('Errors: ', i_error)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqSe7EKCOtDZ"},"source":["## Post-processing of the predicted masks (-> object masks) and code to outline the predicted glands and their identification\n","Two alternative variants\n","- Remove small objects\n","- Separate objects as far as possible (binary intensity morphology)\n","- Outline\n","- Set IDs\n","\n","Binary intensity morphology with module: scipy.ndimage\n","- Separating objects.\n","- Can only differentiate between two states (background and object).\n","- But can emphasize a very specific object and separate it from one another.\n","Konur code with module: skimage.measure\n","- Can outline objects and assign object-specific IDs\n","- Empty areas of the objects can be filled"]},{"cell_type":"code","metadata":{"id":"IMgeW5m-OtDa"},"source":["from scipy import ndimage\n","from importlib import reload\n","import MODULE.JH.image_processing\n","reload(MODULE.JH.image_processing)\n","import MODULE.JH.image_processing as IP"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"COrh2oPPUysC"},"source":["# Lists\n","contour_codes_list=[]\n","# object_filled_list=[]\n","predict_masks_morph_list=[]\n","object_array_list=[]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShBZlKpv132M"},"source":["# VARIANT 2 - contour code (library / module: skimage.measure)\n","# Identification of the objects, variant 2\n","if POST.ident=='measure':\n","    # Fill holes\n","    idObjects= IP.ObjectIDsOfArray()\n","    for idx in range(sample_anzahl):\n","        mask_morph=idObjects.fill_objects(predict_masks[idx], POST.opening_structure)\n","        contur_codes, object_array=idObjects.getObjects(mask_morph)\n","        predict_masks_morph_list.append(mask_morph)\n","        object_array_list.append(object_array)\n","        contour_codes_list.append(contur_codes) \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vi-HcbEoU2i-"},"source":["convert=IP.Convert() # Instance to convert\n","# VARIANT 1: CHAINCODE (Python)\n","if POST.ident=='chain':\n","    for idx in range(sample_anzahl):\n","        mask_morph=ndimage.binary_opening(predict_masks[idx], structure=np.ones(POST.opening_structure)).astype(int)\n","        # -> Returns: 0 = no object or 1 = object\n","        print('\\n--- Mask idx: ', idx)\n","        idObject= IP.IdentifyObject(mask_morph, False) # Klasseninstanz MODUL\n","        # class-id - areas with this id are processed\n","        # id_ - The elements of the area receive this id\n","        chaincodes, object_array, fill_array=idObject.chaincode(class_id=1, id_=1)       # Klassenmethode\n","        # Converts chain code to contour array\n","        contour_codes=convert.chains_to_contourcodes_2(chaincodes)\n","        predict_masks_morph_list.append(mask_morph)\n","        contour_codes_list.append(contour_codes)\n","        object_array_list.append(object_array) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nby3U7SlV11u"},"source":["## Save object arrays and contour codes"]},{"cell_type":"code","metadata":{"id":"Uhx6OdTdOtDh"},"source":["# Control dimensions\n","if VERBOSE:\n","    print('Input images:   ', images_res[0].shape)\n","    print('Actual masks:  ',  actual_masks_res[0].shape)\n","    print('Prediction masks: ', predict_masks[0].shape)\n","    print('Path of model: ', path_model_experiment)\n","    print('Path of result: ', path_result_experiment)\n","\n","# Verzeichnisse zum Abspeichern der Bilder vorbereiten\n","path_inputImages = path_result_experiment / 'images'    # Bilder skaliert entsprechend Trainingsvorgabe\n","path_actualMasks= path_result_experiment / 'actualMasks'        # Tatsächliche Masken\n","path_predictMasks= path_result_experiment / 'predictMasks'      # Prognostizierte Masken\n","path_predictMasksMorph= path_result_experiment / 'predictMasksMorph'          # mit opening (morph)\n","path_predictObjects= path_result_experiment / 'predictObjects'  # Nachbearbeitete prognostizierte Masken\n","path_predictContourCodes = path_result_experiment / 'predictContourCodes' # Kontur der Objekte als Kettencode\n","# New subdirectories    \n","os.chdir(path_result_experiment)\n","os.mkdir(path_inputImages)\n","os.mkdir(path_actualMasks)\n","os.mkdir(path_predictMasks)\n","os.mkdir(path_predictMasksMorph)\n","os.mkdir(path_predictObjects)\n","os.mkdir(path_predictContourCodes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzLbs8ovOtDh"},"source":["from importlib import reload\n","import MODULE.JH.visualize\n","reload(MODULE.JH.visualize)\n","from MODULE.JH.visualize import Show as SHOW\n","show=SHOW(figsize=(18,25))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7A2rtDmOtDh"},"source":["print(len(contour_codes_list)) # Listenelemente\n","print(len(contour_codes_list[0])) # konturen drs Arrays 0'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sk4L9d9cOtDh"},"source":["idx_list=list([25,29,23])\n","#idx_list=list([10,11,12,13])\n","listset=list([images,  actual_masks,         predict_masks, predict_masks_morph_list,  object_array_list])\n","titles=list(['Image', 'Aktual mask', 'Predicted mask', 'with morphology',    'IDs - identify'])\n","path_set= path_result_experiment  / f'images_masks_listset_(P7-04)_{str(idx_list)}.png'\n","show.list_set(idx_list, listset, titles, path=path_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTgv4Nd-OtDh"},"source":["## Save the results"]},{"cell_type":"code","metadata":{"id":"QSf5FQd-OtDh"},"source":["# Images, Masken und Ergebnsimasken der Testbilder speichern\n","for idx in range(sample_anzahl):\n","    print('idx:', idx, end=', ')\n","    # Alle Dateien haben den gleichen Dateinamen,\n","    # werden aber in unterschiedlichen Verzeichnissen gespeichert\n","    file_name=f'result_test_{idx:02d}.png'\n","    # Portieren von ndarray nach *.png\n","    input_image         = Image.fromarray((images_res[idx]*255).astype(np.uint8))\n","    actual_mask_img     = Image.fromarray((actual_masks_res[idx]).astype(np.uint8))\n","    predict_mask_img    = Image.fromarray((predict_masks[idx]).astype(np.uint8))\n","    predict_masks_morph_img = Image.fromarray((predict_masks_morph_list[idx]).astype(np.uint8))\n","    object_image        = Image.fromarray((object_array_list[idx]).astype(np.uint8))\n","    \n","    # Speichern der Arrays=Bilder einschließlich Zwischenergebnisse\n","    input_image.save(path_inputImages / file_name)\n","    actual_mask_img.save(path_actualMasks / file_name)\n","    predict_mask_img.save(path_predictMasks / file_name)\n","    predict_masks_morph_img.save(path_predictMasksMorph / file_name)\n","    object_image.save(path_predictObjects / file_name)\n","    # Code der Konturen \n","    file_name=f'result_test_{idx:02d}.pkl'\n","    file_codes=open(path_predictContourCodes / file_name, 'wb')\n","    pickle.dump(contour_codes_list[idx], file_codes)\n","    file_codes.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCX-wi74OtDi"},"source":["print('ENDE')"],"execution_count":null,"outputs":[]}]}