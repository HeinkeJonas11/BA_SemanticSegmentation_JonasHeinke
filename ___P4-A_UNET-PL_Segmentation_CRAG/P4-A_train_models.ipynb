{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mOHbd3IvxA-"
   },
   "source": [
    "## P4-1 NET-PL mit CRAG_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rO4X1gNbyPsq"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/rtqichen/torchdiffeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTrm3OWD_141"
   },
   "source": [
    "## Netz auswählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dItUCsiTvxA_"
   },
   "outputs": [],
   "source": [
    "TRAIN_RESNET = False\n",
    "TRAIN_UNODE = False\n",
    "TRAIN_UNET = True\n",
    "\n",
    "def get_title():\n",
    "    if TRAIN_UNODE: return 'U-NODE'\n",
    "    elif TRAIN_RESNET: return 'RESNET'\n",
    "    elif TRAIN_UNET: return 'UNET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRo903_k_7pd"
   },
   "source": [
    "## Biliotheken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4TzKO5UvxA_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2aL4J9GvxA_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import PIL\n",
    "import skimage.measure\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from models import ConvODEUNet, ConvResUNet, ODEBlock, Unet\n",
    "#from dataloader import GLaSDataLoader\n",
    "from dataloader_crag import Crag_DataLoader\n",
    "from train_utils import plot_losses\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT7WCHFPhO8B"
   },
   "source": [
    "##Konstanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxO4krf2hSY4"
   },
   "outputs": [],
   "source": [
    "SHAPE_IMG=(3,512, 512) # h=512 # 1024 #752 #758  #752 # orginal 1516 # w=512 # 1024 #752 #754  #752  # orginal 1509\n",
    "SHAPE_MASK=(512, 512)\n",
    "\n",
    "EP=200 #600               # Epochen\n",
    "LR=0.001             # Lernrate  0.0001 lernrate original\n",
    "BL=5                 # Bloecke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntSzt-5pvxA_"
   },
   "source": [
    "## Download the filnames of dataset\n",
    "\n",
    "MILD-Net: \"Colorectal Adenocarcinoma Gland (CRAG) Dataset\"\n",
    "\n",
    "https://warwick.ac.uk/services/its/intranet/projects/webdev/sandbox/juliemoreton/research-copy/tia/data/mildnet\n",
    "\n",
    "Datenset zum Herunterladen:\n",
    "\n",
    "https://drive.google.com/u/0/uc?id=1p3dZXpgeA1IcGO6vXhStbVLMku-fZTmQ&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLkJJvJTvxA_"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('CRAG_v2'):\n",
    "    print('Bitte laden sie das Datenset in das Projektverzeichnis!')\n",
    "    print('Das Verzeichnis lautet \"CRAG_v2\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8Gfu6y_vxA_"
   },
   "outputs": [],
   "source": [
    "from jh_path import Path as PATH   # Pfade und Dateinamen\n",
    "path=PATH() # Instanz der Klasse für Methodenaufruf erforderlich\n",
    "\n",
    "path_images=PATH.dataset / 'train/Images/'\n",
    "path_targets=PATH.dataset / 'train/Annotation/'\n",
    "# input and target files\n",
    "filenames_inputs  =path.get_filenames(path=path_images , dateifilter= '*.png')\n",
    "filenames_targets =path.get_filenames(path=path_targets ,dateifilter='*.png')\n",
    "# sicherstellen, dass beide Listen die gleiche Länge besitzen.\n",
    "print('Anzahl der Bilder      : ', len(filenames_inputs))\n",
    "print('Anzahl der Annotationen: ', len(filenames_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79hvZUEvvxBA"
   },
   "source": [
    "## Dateipfade aufteilen in Trainings- und Validierungsdateipfade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5pv-roEvxBA"
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "val_set_idx = torch.LongTensor(10).random_(0, len(filenames_inputs)) #+\n",
    "train_set_idx = torch.arange(0, len(filenames_inputs)) #+\n",
    "\n",
    "overlapping = (train_set_idx[..., None] == val_set_idx).any(-1)\n",
    "train_set_idx = torch.masked_select(train_set_idx, ~overlapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWqjwFKKvxBA"
   },
   "source": [
    "## Define datasets and dataloaders #+\n",
    "- Datenset WARWIEK qu: Originalbilder (hxw) 522 x 775 (1,485)-> scaliert auf 352x512 (1,455), scal:1,48/1.58\n",
    "- Datenset CRAG_v2   : Originalbilder (hxw) 1516x1509 (0,995)-> skaliert auf a), b), c)\n",
    "- a) ->  352x512 (1,455), scal: \n",
    "- c) ->  752x752 (1,000), scal: 2,0\n",
    "- d) -> 1024x1024 (1)  , scal: 1.5\n",
    "- e) ->  512 x512 (1) , scal: 2,95\n",
    "- f) ->  256 x256 (1)  , scal: 5,9\n",
    "\n",
    "num_workers hardwareabhängig auf 8 gesetzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXShGevBvxBA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainset = Crag_DataLoader(filenames_inputs,filenames_targets,SHAPE_MASK, dataset_repeat=1, images=train_set_idx)\n",
    "valset = Crag_DataLoader(filenames_inputs,filenames_targets,SHAPE_MASK, dataset_repeat=1, images=val_set_idx, validation=True)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=4)   ## Batchsize größer setzen? Batchsize original 1\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA9ieMcevxBA"
   },
   "source": [
    "# Plotting train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8fwo7s5vxBA"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=6, figsize=(24, 15))\n",
    "\n",
    "for y in range(5): # y ist idx einer Stichprobe\n",
    "    for x in range(3):  \n",
    "        sample = trainset[y]\n",
    "        ax[y, x * 2].imshow(sample[0].numpy().transpose(1,2,0))\n",
    "        ax[y, x * 2 + 1].imshow(sample[1][0])\n",
    "        ax[y, x * 2].axis('off')\n",
    "        ax[y, x * 2 + 1].axis('off')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW7YXVJzvxBB"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(24, 15))\n",
    "\n",
    "sample = trainset[0]\n",
    "ax[1].imshow(sample[1][0].numpy())\n",
    "ax[2].imshow(sample[1].sum(dim=0))\n",
    "ax[0].imshow(sample[0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80fNjfxhvxBB"
   },
   "source": [
    "# Plotting validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ntz5MfGmvxBB"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=6, figsize=(24, 15))\n",
    "\n",
    "for y in range(5):\n",
    "    for x in range(3):\n",
    "        sample = valset[y]\n",
    "        ax[y, x * 2].imshow(sample[0].numpy().transpose(1,2,0))\n",
    "        ax[y, x * 2 + 1].imshow(sample[1][1])\n",
    "        ax[y, x * 2].axis('off')\n",
    "        ax[y, x * 2 + 1].axis('off')\n",
    "\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzYMr1MSvxBB"
   },
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sh1Ys5bLvxBB"
   },
   "outputs": [],
   "source": [
    "devicename='cuda'\n",
    "device = torch.device(devicename)\n",
    "\n",
    "if TRAIN_UNODE:\n",
    "    net = ConvODEUNet(num_filters=16, output_dim=2, time_dependent=True, \n",
    "                      non_linearity='lrelu', adjoint=True, tol=1e-3)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wDXI-GsvxBB"
   },
   "outputs": [],
   "source": [
    "if TRAIN_RESNET:\n",
    "    net = ConvResUNet(num_filters=16, output_dim=2, non_linearity='lrelu')\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpYXfADPvxBB"
   },
   "outputs": [],
   "source": [
    "if TRAIN_UNET:\n",
    "    net = Unet(depth=BL, num_filters=64, output_dim=2).cuda()\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDGYhZA6i7nh"
   },
   "source": [
    "## Modell zeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLJUDFGNi-X3"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "#-# summary = summary(net, (3,512, 512), device='cuda')\n",
    "summary = summary(net, SHAPE_IMG, device=devicename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjIgiVwojbNw"
   },
   "source": [
    "## Verarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M2E1GLyvxBC"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WH2tWHWrvxBC"
   },
   "outputs": [],
   "source": [
    "for m in net.modules():\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbKY7q72vxBC"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH5bxLwrvxBC"
   },
   "outputs": [],
   "source": [
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C26A7YJTvxBC"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd5X8SBavxBC"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "val_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "if TRAIN_UNET:\n",
    "    cross_entropy = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def criterion(conf, labels):\n",
    "        out_shape = conf.shape[2:4]\n",
    "        label_shape = labels.shape[2:4]\n",
    "\n",
    "        w = (label_shape[1] - out_shape[1]) // 2\n",
    "        h = (label_shape[1] - out_shape[1]) // 2\n",
    "        dh, dw = out_shape[0:2]\n",
    "\n",
    "        conf_loss_ce = cross_entropy(conf, labels[:, :, h:h+dh, w:w+dw])\n",
    "\n",
    "        return conf_loss_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHyXg0eYvxBD"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5hko9SdvxBD"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvIe1FUgvxBD"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "nfe = [[],[],[],[],[],[],[],[],[]] if TRAIN_UNODE else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNi_u4vAvxBD"
   },
   "outputs": [],
   "source": [
    "accumulate_batch = 8  # 8  # mini-batch size by gradient accumulation\n",
    "accumulated = 0\n",
    "\n",
    "if TRAIN_RESNET: filename = 'best_border_resnet_model.pt'\n",
    "elif TRAIN_UNODE: filename = 'best_border_unode_model.pt'\n",
    "elif TRAIN_UNET: filename = 'best_border_unet_model.pt'\n",
    "\n",
    "def run(lr=1e-3, epochs=100):\n",
    "    accumulated = 0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # training loop with gradient accumulation\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        for data in tqdm(trainloader):\n",
    "            inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels) / accumulate_batch\n",
    "            loss.backward()\n",
    "            accumulated += 1\n",
    "            if accumulated == accumulate_batch:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                accumulated = 0\n",
    "\n",
    "            running_loss += loss.item() * accumulate_batch\n",
    "\n",
    "        losses.append(running_loss / len(trainloader))\n",
    "        \n",
    "        # validation loop\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.0\n",
    "            for data in valloader:\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            val_losses.append(running_loss / len(valloader))\n",
    "            # Bedingung zum Speichern des Modells\n",
    "            if np.argmin(val_losses) == len(val_losses) - 1 and loss < 0.4:\n",
    "                torch.save(net, filename)\n",
    "                #------Protokoll--------------------------\n",
    "                protokolldatei = open('_protokoll.txt','a') #+\n",
    "                protokolldatei.write('---------------------------------------------\\n')  #+\n",
    "                protokolldatei.write(f'Speicherung des Modells nach {epoch} Epochen, loss: {loss}\\n') #+\n",
    "                protokolldatei.close() #+\n",
    "                #-------------------------------------\n",
    "                \n",
    "            clear_output(wait=True)\n",
    "            plot_losses(inputs, outputs, losses, val_losses, get_title(), nfe, net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxl0tPEXCVwO"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "protokoll_train = open(f'(4-1)_protokoll{SHAPE_IMG}.txt', mode='w')\n",
    "protokoll_train.write(f'--- Projekt 3-1 --- Shape: {SHAPE_IMG}, {SHAPE_IMG}, Epochen: {EP}, Lernrate: {LR}  ---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sJCcPFhvxBD"
   },
   "outputs": [],
   "source": [
    "if TRAIN_UNODE or TRAIN_RESNET: lr = LR * 10 # 1e-3\n",
    "else: lr = LR # 1e-4\n",
    "protokoll_train.write(f'Training start: {datetime.datetime.now()}\\n')\n",
    "# Training starten\n",
    "run(lr, EP - len(losses))\n",
    "protokoll_train.write(f'Training end:   {datetime.datetime.now()}\\n')\n",
    "protokoll_train.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm5wwtnkvxBE"
   },
   "source": [
    "## Calculate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsFs5B29vxBE"
   },
   "outputs": [],
   "source": [
    "# load best model\n",
    "net = torch.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0s1jge8vxBE"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(valloader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(\"Check validation loss:\", running_loss / len(valloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fol4epEvxBE"
   },
   "source": [
    "## Visualize results on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuhifPtwvxBE"
   },
   "outputs": [],
   "source": [
    "#+ from inference_utils import inference_image, postprocess\n",
    "from inference_utils_crag import inference_image, postprocess #+\n",
    "import numpy as np              #+\n",
    "import matplotlib.pyplot as plt #*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiEjH_FAvxBE"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=3, figsize=(4*3,3*5))\n",
    "\n",
    "ax[0, 0].set_title('Image')\n",
    "ax[0, 1].set_title('Ground-truth')\n",
    "ax[0, 2].set_title(get_title())\n",
    "\n",
    "for col in range(3):\n",
    "    for row in range(5):\n",
    "        index = val_set_idx[row]\n",
    "        print(f'idx: {index}, ', end='')\n",
    "        image = PIL.Image.open(path_images /  f'train_{index}.png')\n",
    "        gt = PIL.Image.open(path_targets / f'train_{index}.png')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #? result, input_image = inference_image(net, image, shouldpad=TRAIN_UNET)\n",
    "            result, input_image  = inference_image(net, image, shouldpad=TRAIN_UNET)\n",
    "            result = postprocess(result, gt)\n",
    "        if col == 0:\n",
    "            ax[row, col].imshow(image)\n",
    "        elif col == 1:\n",
    "            ax[row, col].imshow(np.array(gt) > 0)\n",
    "        else:\n",
    "            ax[row, col].imshow(image)\n",
    "            ax[row, col].imshow(result, alpha=0.5)\n",
    "                \n",
    "        ax[row, col].set_axis_off()\n",
    "        \n",
    "\n",
    "\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGN5meRsvxBE"
   },
   "source": [
    "# Calculate metrics on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hH9Uotx8vxBE"
   },
   "outputs": [],
   "source": [
    "from metrics import ObjectDice, ObjectHausdorff, F1score\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "import skimage.measure\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from inference_utils_crag import inference_image, postprocess\n",
    "import matplotlib.pyplot as plt\n",
    "########################################################\n",
    "from img_array_transform_jh import ArrayTransform as TRANSFORM\n",
    "from _path import Path as PATH   # Pfade und Dateinamen\n",
    "path=PATH() # Instanz der Klasse für Methodenaufruf erforderlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rNuWDX9vxBF"
   },
   "outputs": [],
   "source": [
    "TEST_RESNET = False\n",
    "TEST_UNODE = False\n",
    "TEST_UNET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7O09nRBvxBF"
   },
   "outputs": [],
   "source": [
    "if TEST_UNODE: net = torch.load('best_border_unode_model.pt')\n",
    "elif TEST_RESNET: net = torch.load('best_border_resnet_model.pt')\n",
    "elif TEST_UNET: net = torch.load('best_border_unet_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2InFo2e1vxBF"
   },
   "outputs": [],
   "source": [
    "path_testimages=PATH.dataset / 'valid/Images/'\n",
    "path_testtargets=PATH.dataset / 'valid/Annotation/'\n",
    "\n",
    "filenames_testinputs  =path.get_filenames(path=path_testimages , dateifilter= '*.png')\n",
    "filenames_testtargets =path.get_filenames(path=path_testtargets ,dateifilter='*.png')\n",
    "\n",
    "print('Anzahl der Bilder      : ', len(filenames_testinputs))\n",
    "print('Anzahl der Annotationen: ', len(filenames_testtargets))\n",
    "\n",
    "anzahl_testimages=len(filenames_testinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BS73H34SvxBF"
   },
   "outputs": [],
   "source": [
    "# Visualisierung (jh)\n",
    "\n",
    "idx=12\n",
    "fname=f'test_{idx}.png'\n",
    "\n",
    "image = PIL.Image.open(path_testimages /  fname)\n",
    "gt = PIL.Image.open(path_testtargets / fname)\n",
    "\n",
    "result, resized = inference_image(net, image, shouldpad=TEST_UNET)\n",
    "result = postprocess(result, gt)\n",
    "gt = skimage.measure.label(np.array(gt))\n",
    "\n",
    "print('result: ', result.shape)\n",
    "print('gt: ', gt.size)\n",
    "print('image: ', image.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGPbac0QvxBG"
   },
   "outputs": [],
   "source": [
    "# Visualisierung (jh)\n",
    "transform=TRANSFORM()\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(221).set_title('Image')\n",
    "plt.imshow(image)\n",
    "\n",
    "# Achtung: Drüsen der tatsächliche Maske sind indiziert !!\n",
    "plt.subplot(222).set_title('tatsächliche Maske') \n",
    "plt.imshow(gt)\n",
    "\n",
    "# Klassifizierung (0- Hintergrund, 1- Drüsen)\n",
    "plt.subplot(223).set_title('tatsächliche Maske, binär') \n",
    "plt.imshow(transform.twoClasses(gt))\n",
    "\n",
    "plt.subplot(224).set_title('prognostizierte Maske, binär')\n",
    "plt.imshow(transform.twoClasses(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gvnxp7xhvxBG"
   },
   "source": [
    "### Identnummernbezogene/Objektbezogene Bewertung\n",
    "[ Id0 - Hintergrund, Durchnummerierung der Drüsen je maske von Id=1, 2 , 3 , ..., n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ird7nHnwkHJg"
   },
   "outputs": [],
   "source": [
    "protokolldatei = open(f'protokoll_prognose{SHAPE_MASK}.txt','w')\n",
    "\n",
    "protokolldatei.write('\\nObjektbezogenen Kennzahlen:\\n')\n",
    "# Tabellenkopf\n",
    "print_string=(f' idx | dice_img  | f1_img    | hausdorff_img ')\n",
    "protokolldatei.write(print_string+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i86QbIuuvxBG"
   },
   "outputs": [],
   "source": [
    "\n",
    "dice, hausdorff, f1, dice_full = 0, 0, 0, 0\n",
    "\n",
    "if TEST_UNODE: folder = 'results_unode'\n",
    "elif TEST_UNET: folder = 'results_unet'\n",
    "elif TEST_RESNET: folder = 'results_resnet'\n",
    "    \n",
    "names = []\n",
    "i_error=0\n",
    "anzahl=0\n",
    "\n",
    "for index in np.arange(1, anzahl_testimages+1):\n",
    "    names.append(f'test_{index}.png')\n",
    "  \n",
    " \n",
    "for i, fname in tqdm_notebook(enumerate(names), total=anzahl_testimages):\n",
    "    # tqdm.notebook.tqdm \n",
    "    # print(f'idx: {i}, ', end='') #\n",
    "    image = PIL.Image.open(path_testimages /  fname)\n",
    "    gt = PIL.Image.open(path_testtargets / fname)\n",
    "    \n",
    "    result, resized = inference_image(net, image, shouldpad=TEST_UNET)\n",
    "    result = postprocess(result, gt)2.201\n",
    "    \n",
    "    \n",
    "    gt = skimage.measure.label(np.array(gt))\n",
    "    \n",
    "\n",
    "    #-# f1_img, hausdorff_img, dice_img =0, 0, 0\n",
    "    try:\n",
    "\n",
    "        f1_img = F1score(result, gt)\n",
    "        hausdorff_img = ObjectHausdorff(result, gt)\n",
    "        dice_img = ObjectDice(result, gt)\n",
    "        \n",
    "        f1 += f1_img\n",
    "        hausdorff += hausdorff_img\n",
    "        dice += dice_img\n",
    "        print(i,', ', fname,' : ', f1_img, hausdorff_img, dice_img)\n",
    "        anzahl +=1\n",
    "        \n",
    "        #------Protokoll--------------------------\n",
    "        print_string=(f' {i:3d} | {dice_img:9.3f} | {f1_img:9.3f} | {hausdorff_img:13.3f} ')\n",
    "        print(print_string)\n",
    "        # --- Protokoll ---\n",
    "        protokolldatei.write(print_string+'\\n')\n",
    "\n",
    "    except:\n",
    "        i_error +=1\n",
    "        print('Error: ',i_error, 'Zyklus: ', i, 'Dateiname: ', fname)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uslql5wnvxBG"
   },
   "outputs": [],
   "source": [
    "print('--Mittelwerte, Drüsen- bzw. Identnummernbezogen------------------------------------')\n",
    "print('ObjectDice:', dice / anzahl )\n",
    "print('Hausdorff:', hausdorff / anzahl)\n",
    "print('F1:', f1 / anzahl )\n",
    "print('Anzahl io.: ', anzahl)\n",
    "print('Errors: ', i_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiQ9MLMPk32_"
   },
   "outputs": [],
   "source": [
    "protokolldatei.write('\\n Mittelwerte, Objektbezogenen Kennzahlen (OB):\\n')\n",
    "protokolldatei.write(f'ObjectDice: { dice / anzahl }\\n')\n",
    "protokolldatei.write(f'Hausdorff: {hausdorff / anzahl}\\n')\n",
    "protokolldatei.write(f'F1: {f1 / anzahl}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMziT3U9vxBG"
   },
   "source": [
    "### Klassenbezogene Bewertung\n",
    "[0 - Hintergrund, 1- Drüsen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcrbnLDElA3_"
   },
   "outputs": [],
   "source": [
    "protokolldatei.write('\\nKlassenbezogenen Kennzahlen (KB):\\n')\n",
    "# Tabellenkopf\n",
    "print_string=(f' idx | dice_img  | f1_img    | hausdorff_img ')\n",
    "protokolldatei.write(print_string+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHKOzVOkvxBG"
   },
   "outputs": [],
   "source": [
    "dice, hausdorff, f1, dice_full = 0, 0, 0, 0\n",
    "\n",
    "if TEST_UNODE: folder = 'results_unode'\n",
    "elif TEST_UNET: folder = 'results_unet'\n",
    "elif TEST_RESNET: folder = 'results_resnet'\n",
    "    \n",
    "names = []\n",
    "i_error=0\n",
    "anzahl=0\n",
    "\n",
    "for index in np.arange(1, anzahl_testimages+1):\n",
    "    names.append(f'test_{index}.png')\n",
    "  \n",
    " \n",
    "for i, fname in tqdm_notebook(enumerate(names), total=anzahl_testimages):\n",
    "    # tqdm.notebook.tqdm \n",
    "    # print(f'idx: {i}, ', end='') #\n",
    "    image = PIL.Image.open(path_testimages /  fname)\n",
    "    gt = PIL.Image.open(path_testtargets / fname)\n",
    "    \n",
    "    result, resized = inference_image(net, image, shouldpad=TEST_UNET)\n",
    "    result = postprocess(result, gt)\n",
    "    \n",
    "    \n",
    "    gt = skimage.measure.label(np.array(gt))\n",
    "    \n",
    "    # To Binaer, da nur Hintergund (0) und Drüsen (1) (JH)\n",
    "    gt= transform.twoClasses(gt)\n",
    "    result= transform.twoClasses(result)\n",
    "\n",
    "    #-# f1_img, hausdorff_img, dice_img =0, 0, 0\n",
    "    try:\n",
    "\n",
    "        f1_img = F1score(result, gt)\n",
    "        hausdorff_img = ObjectHausdorff(result, gt)\n",
    "        dice_img = ObjectDice(result, gt)\n",
    "        \n",
    "        f1 += f1_img\n",
    "        hausdorff += hausdorff_img\n",
    "        dice += dice_img\n",
    "        print(i,', ', fname,' : ', f1_img, hausdorff_img, dice_img)\n",
    "        anzahl +=1\n",
    "        \n",
    "        #------Protokoll--------------------------\n",
    "        print_string=(f' {i:3d} | {dice_img:9.3f} | {f1_img:9.3f} | {hausdorff_img:13.3f} ')\n",
    "        print(print_string)\n",
    "        # --- Protokoll ---\n",
    "        protokolldatei.write(print_string+'\\n')\n",
    "        #-------------------------------------\n",
    "\n",
    "    except:\n",
    "        i_error +=1\n",
    "        print('Error: ',i_error, 'Zyklus: ', i, 'Dateiname: ', fname)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-eNQ4dJUvxBH"
   },
   "outputs": [],
   "source": [
    "print('--Mittelwerte, Klassenbezogen -----------------------------------')\n",
    "print('ObjectDice:', dice / anzahl )\n",
    "print('Hausdorff:', hausdorff / anzahl)\n",
    "print('F1:', f1 / anzahl )\n",
    "print('Anzahl io.: ', anzahl)\n",
    "print('Errors: ', i_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNL7z2MylU3g"
   },
   "outputs": [],
   "source": [
    "protokolldatei.write('\\n Mittelwerte, klassenbezogene Kennzahlen (KB): \\n')\n",
    "protokolldatei.write(f'ObjectDice: {dice / anzahl}\\n')\n",
    "protokolldatei.write(f'Hausdorff: {hausdorff / anzahl}\\n')\n",
    "protokolldatei.write(f'F1: {f1 / anzahl}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gznJWbcQlyD0"
   },
   "outputs": [],
   "source": [
    "protokolldatei.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeUzh-NBl1zm"
   },
   "source": [
    "## Visualisierung 1 mit Zwischendarstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYC8uPV2l9vO"
   },
   "outputs": [],
   "source": [
    "def showPrognose(result_prog):\n",
    "    '''Zum Visualisieren des Prognoseergbnisses ohne Nachbearbeitung (ohne Postprozess) (JH)'''\n",
    "    #print(result_1.shape)\n",
    "    kanal=np.zeros((1,result_prog.shape[1], result_prog.shape[2]))\n",
    "    result_prog=np.concatenate((result_prog, kanal))\n",
    "    result_prog=result_prog.transpose((2,1,0))\n",
    "    result_prog=np.rot90(result_prog,k=1)\n",
    "    result_prog=np.flip(result_prog, 0)\n",
    "    return result_prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrSdBOP6mG82"
   },
   "outputs": [],
   "source": [
    "images, gts, results_prog, results=[],[],[],[]\n",
    "for idx in range(len(filenames_testinputs)):\n",
    "  #image = PIL.Image.open(filenames_testinputs[idx])\n",
    "  #gt = PIL.Image.open(filenames_testtargets[idx])\n",
    "  fnameimage= str(path_testimages) + f'/test_{idx+1}.png'\n",
    "  fnamemask= str(path_testtargets) + f'/test_{idx+1}.png'\n",
    "  image = PIL.Image.open(fnameimage)\n",
    "  gt = PIL.Image.open(fnamemask) \n",
    "  with torch.no_grad():\n",
    "      # Prognose\n",
    "      result_prog, input_image = inference_image(net, image, shouldpad=TRAIN_UNET)\n",
    "      # Nachbearbeitung\n",
    "      result = postprocess(result_prog, gt)\n",
    "  images.append(image)\n",
    "  gts.append(gt)\n",
    "\n",
    "  # Zum Visualisieren des Prognoseergbnisses ohne Nachbearbeitung \n",
    "  result_prog=showPrognose(result_prog)\n",
    "\n",
    "  results_prog.append(result_prog)\n",
    "  results.append(result)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KzDXpgbm4L3"
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import MODULE.JH.visualize\n",
    "reload(MODULE.JH.visualize)\n",
    "\n",
    "from MODULE.JH.visualize import Show as SHOW\n",
    "\n",
    "show=SHOW(experiment='', figsize=(15,15), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSKzy2Lsm5BG"
   },
   "outputs": [],
   "source": [
    "idx_list=list([12,22,26])\n",
    "path_set= f'(4-1)_images_masks_listset_{str(idx_list)}.png'\n",
    "\n",
    "listset=list([images, gts, results_prog, results])\n",
    "titles=list(['Image', 'tatsächliche Maske','prognostizierte Maske', 'mit Postprocessing'])\n",
    "\n",
    "show.list_set(idx_list, listset,titles, path=path_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3GthqJ1m_Me"
   },
   "source": [
    "### Alternative Darstellung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyJyGQXKm_0e"
   },
   "outputs": [],
   "source": [
    "show=SHOW(experiment='', figsize=(15,11), fontsize=14)\n",
    "path_set= f'(1-1)_images_masks_Objekte_{str(idx_list)}.png'\n",
    "\n",
    "listset=list([images, gts, results])\n",
    "titles=list(['Image', 'tatsächliche Maske','Prognose mit Postprocessing'])\n",
    "\n",
    "show.list_set(idx_list, listset,titles, path=path_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8nYeLlqvxBH"
   },
   "source": [
    "### Visualisierung 2, horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mucsw8ctvxBH"
   },
   "outputs": [],
   "source": [
    "# Ergänzung: Ausgabe von Images und Masken für das Skript (JH)\n",
    "\n",
    "path_testimages=PATH.dataset / 'valid/Images/'\n",
    "path_testtargets=PATH.dataset / 'valid/Annotation/'\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(4*3,4*3))\n",
    "samples=[6, 26, 23]\n",
    "\n",
    "\n",
    "for col in range(3):\n",
    "    for row in range(3):\n",
    "        #index = val_set_idx[samples[row]]\n",
    "        ax[row, 0].set_title(f'Image {samples[row]}')\n",
    "        ax[row, 1].set_title(f'tatsächliche Maske {samples[row]}')\n",
    "        ax[row, 2].set_title(f'prognostizierte Maske {samples[row]}')\n",
    "        \n",
    "        index = samples[row]\n",
    "        \n",
    "        #fname=f'test_{idx}.png'\n",
    "        fnameimage= str(path_testimages) + f'/test_{index+1}.png'\n",
    "        fnamemask= str(path_testtargets) + f'/test_{index+1}.png'\n",
    "        \n",
    "      \n",
    "        image = PIL.Image.open(fnameimage)\n",
    "        gt = PIL.Image.open(fnamemask)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            result, input_image = inference_image(net, image, shouldpad=TRAIN_UNET)\n",
    "            result = postprocess(result, gt)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            result, input_image = inference_image(net, image, shouldpad=TRAIN_UNET)\n",
    "            result = postprocess(result, gt)\n",
    "        if col == 0:\n",
    "            ax[row, col].imshow(image)\n",
    "        elif col == 1:\n",
    "            #ax[row, col].imshow(np.array(gt) > 0)\n",
    "            ax[row, col].imshow(np.array(gt))\n",
    "        else:\n",
    "            ax[row, col].imshow(image)\n",
    "            ax[row, col].imshow(result, alpha=1)\n",
    "                \n",
    "        ax[row, col].set_axis_off()\n",
    "\n",
    "plt.savefig(f'Test_Image_Maske_Prognose{samples}.png', bbox_inches=\"tight\")\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbG5SP7UvxBH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyOVHQ7BvxBH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "P4-A_train_models(512x512ep600).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
